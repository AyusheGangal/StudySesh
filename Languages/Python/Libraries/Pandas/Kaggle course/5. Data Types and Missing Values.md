# Dtypes
The data type for a column in a DataFrame or a Series is known as the **dtype**.

You can use the `dtype` property to grab the type of a specific column. For instance, we can get the dtype of the `price` column in the `reviews` DataFrame:

```Python
reviews.price.dtype
```
```text
dtype('float64')
```

Alternatively, the `dtypes` property returns the `dtype` of _every_ column in the DataFrame:
```Python
reviews.dtypes
```

Data types tell us something about how pandas is storing the data internally. `float64` means that it's using a 64-bit floating point number; `int64` means a similarly sized integer instead, and so on.

One peculiarity to keep in mind (and on display very clearly here) is that columns consisting entirely of strings do not get their own type; they are instead given the `object` type.

It's possible to convert a column of one type into another wherever such a conversion makes sense by using the `astype()` function. For example, we may transform the `points` column from its existing `int64` data type into a `float64` data type:

```Python
reviews.points.astype('float64')
```

A DataFrame or Series index has its own `dtype`, too:
```Python
reviews.index.dtype
```

# Missing data
Entries missing values are given the value `NaN`, short for "Not a Number". For technical reasons these `NaN` values are always of the `float64` dtype.

Pandas provides some methods specific to missing data. To select `NaN` entries you can use `pd.isnull()` (or its companion `pd.notnull()`). This is meant to be used thusly:

```Python
reviews[pd.isnull(reviews.country)]
```

Replacing missing values is a common operation. Pandas provides a really handy method for this problem: `fillna()`. `fillna()` provides a few different strategies for mitigating such data. For example, we can simply replace each `NaN` with an `"Unknown"`:
```Python
reviews.region_2.fillna("Unknown")
```

Or we could fill each missing value with the first non-null value that appears sometime after the given record in the database. This is known as the [[backfill strategy]].

Alternatively, we may have a non-null value that we would like to replace. For example, suppose that since this dataset was published, reviewer Kerin O'Keefe has changed her Twitter handle from `@kerinokeefe` to `@kerino`. One way to reflect this in the dataset is using the `replace()` method:

```Python
reviews.taster_twitter_handle.replace("@kerinokeefe", "@kerino")
```

The `replace()` method is worth mentioning here because it's handy for replacing missing data which is given some kind of sentinel value in the dataset: things like `"Unknown"`, `"Undisclosed"`, `"Invalid"`, and so on.

## Exercises
1. What is the data type of the `points` column in the dataset?
```Python
dtype = reviews.points.dtype
```

2. Create a Series from entries in the `points` column, but convert the entries to strings. Hint: strings are `str` in native Python.
```Python
point_strings = reviews.points.astype('str')
```

3. Sometimes the price column is null. How many reviews in the dataset are missing a price?
```Python
n_missing_prices = len(reviews[pd.isnull(reviews.price)])
```

4. What are the most common wine-producing regions? Create a Series counting the number of times each value occurs in the `region_1` field. This field is often missing data, so replace missing values with `Unknown`. Sort in descending order. Your output should look something like this:

```
Unknown                    21247
Napa Valley                 4480
                           ...  
Bardolino Superiore            1
Primitivo del Tarantino        1
Name: region_1, Length: 1230, dtype: int64
```

```Python
reviews_per_region = reviews.fillna("Unknown").region_1.value_counts().sort_values(ascending=False)
```
