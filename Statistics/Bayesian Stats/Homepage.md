https://www.youtube.com/watch?v=U1HbB0ATZ_A&list=PLFDbGp5YzjqXQ4oE4w9GVWdiokWB9gEpm


### Bayesian Stats Syllabus
![[Screenshot 2023-04-18 at 7.37.45 PM.png|300]]

The entirety of the syllabus is based around the given Bayesian formula. 
The goal of any sort of Bayesian inference is to derive the `Posterior Distribution` 
= P($\theta$ | data).
It means that we are trying to assign a probability density value to all different values of theta so that we obtain a curve like this for theta values and probability density function
![[Screenshot 2023-04-18 at 7.42.01 PM.png|200]]

P(data|$\theta)$ = Likelihood
<mark style="background: #D2B3FFA6;">chatGPT: </mark>Likelihood is a term used in statistics to describe the probability of observing a particular set of data given a specific set of parameter values in a statistical model. It is often denoted by the symbol L and is a function of the parameters of the model.

In simpler terms, the likelihood represents how well the observed data fits the proposed model. A higher likelihood indicates that the observed data is more probable to occur under the given model assumptions, while a lower likelihood indicates the opposite. The likelihood function is often used in maximum likelihood estimation, which is a method of estimating the parameters of a statistical model by maximizing the likelihood function.

P($\theta$) = Prior. it represents our experiment knowledge of the parameter values.

>[!note]
>As the amount of data you collect increases then the prior plays less and less important role in terms of its determination of the poterior.

P(data) = denominator is the most difficult. 