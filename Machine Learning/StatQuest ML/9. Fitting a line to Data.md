Fitting a line to data aka Least Squares aka Linear Regression

- Least Squares is a method used to find the best-fitting solution to a set of observations by minimizing the sum of the squared differences (errors) between the observed values and the predicted values.

![[Screen Shot 2024-12-23 at 19.17.33 PM.png]]

Given some data, how do we decide which line to use to fit the data?
- Starting with a horizontal line, which cuts through our average Y value (here, 3.5). Let's call it $b$. 
- Therefore, the y value for this line is b, or in equation format $y = b = 3.5$
- We can measure how well this line fits the data by seeing how close it is to the actual data points.
- The distance between the line and $1^{st}$ data point ($x_1, y_1$) is $b - y_1$
- We square these distances, so the points which are above the line do not cancel out the error (which means it can incorrectly say that it is good fit overall when it is not), so we square the distances to keep them positive.
- Below is the measure of how well the line fits the curve
	![[Screen Shot 2024-12-23 at 19.12.48 PM.png|500]]

>[! Note]
>This is called as the "Sum of Square Residuals", because the [[Residuals]] are the differences between the real data and the line, and we are summing the square of these values.

This line will fit the data better or worse if we rotate it. To find the optimal value,
Let us take a generic equation of a line: $y = a*x + b$
	Where, a is the slope & b is the y-intercept.
	
![[Screen Shot 2024-12-23 at 19.14.16 PM.png|400]]

**Aim: We want to find the optimal value for $a$ and $b$ so that we minimize the sum of squared residuals.**
putting the equation of line in the formula used before,
![[Screen Shot 2024-12-23 at 19.34.53 PM.png|500]]
- The term $(a*x_1 + b)$ is the value of the line at $x_1$. 
- $y_1$ is the observed value at $x_1$. 

>[! Note]
>Since we want the line that will give us the smallest sum of squares, this method for finding the best values of $a$ and $b$ is called "Least Squares".


If we plotted the sum of squared residuals vs each rotation of the line, we would get:
![[Screen Shot 2024-12-23 at 19.39.38 PM.png|400]]
- To find the optimal rotation of this line, we take the derivative of this function. 
- The derivative tells us the slope of the function at every point.
- The optimal solution occurs when the slope is 0.
- ![[Screen Shot 2024-12-23 at 19.42.02 PM.png|400]]

### Important Concepts:
1. We want to minimize the squares of the distance between the observed values and the line.
2. We do this by taking the derivative and finding where it is equal to 0.
3. The final line minimizes the sums of squared residuals (it gives the "least squares") between it and the real data points.