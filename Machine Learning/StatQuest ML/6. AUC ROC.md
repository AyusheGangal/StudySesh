Starting with some data on mice. The blue dots representing "Obese" mice and red dots representing "Not Obese" mice Along the X-axis, we have weight of the mice. 

![[Screen Shot 2024-12-22 at 14.45.08 PM.png|400]]
![[Screen Shot 2024-12-22 at 14.45.57 PM.png|400]]

### Fitting a Logistic regression curve to this data
![[Screen Shot 2024-12-22 at 14.52.39 PM.png|400]]

- When we implement Logistic Regression, the Y-axis is converted to the probability that a mouse is obese or not. 
- Logistic Regression is a Classification algorithm, which tells us the probability of whether the mouse if obese or not based on its weight (here).![[Screen Shot 2024-12-22 at 14.55.01 PM.png|400]]

- Therefore, we can use the logistic regression curve to tell us the "Probability" that a mouse is obese or not based on its weight.
	![[Screen Shot 2024-12-22 at 14.56.45 PM.png|400]]

However, if we want to classify the mice as "Obese" or "Not Obese", then we need a way to turn these probabilities into classifications (predictions).
- One way to classify mice is **set a threshold** value.

### Setting threshold of 0.5
- ![[Screen Shot 2024-12-22 at 15.00.25 PM.png|400]]
	And classify all mice as "Obese" with a probability of being obese > 0.5 as "Obese". 
	And classify all mice as "Not Obese" with a probability of being not obese <= 0.5 as "Not Obese".

To evaluate the effectiveness of the Logistic Regression with a classification threshold set to 0.5, we can test it with mice that we know are obese or not obese. 
![[Screen Shot 2024-12-22 at 15.05.56 PM.png|400]]

Creating a confusion matrix to summarize the classifications,![[Screen Shot 2024-12-22 at 15.07.05 PM.png|400]]

Using this confusion matrix to calculate sensitivity and specificity to evaluate Logistic Regression with classification threshold of 0.5 for obesity.

### Setting threshold of 0.1
- If we were to use a classification threshold of 0.1 instead, we would have correct classifications for all 4 obese mice, but will also increase the number of false positives. 
- The lower threshold would also reduce the number of False Negatives, because all the obese mice were correctly classified.
	![[Screen Shot 2024-12-22 at 15.22.15 PM.png|400]]

### Setting threshold of 0.9
![[Screen Shot 2024-12-22 at 15.24.33 PM.png|400]]

- In this case, we would correctly classify the same number of obese samples as when the threshold was set to 0.5, but we would not have False-Positives. 
- And we would correctly classify one more sample that was not obese.
- Also will have the same number of False-Negatives as before.
- ![[Screen Shot 2024-12-22 at 15.27.59 PM.png|400]]

With this data, we find that a higher threshold does a better job classifying samples as obese or not obese.

### How to determine which threshold value to choose
- We don't need to test every single option, as some thresholds might result in the same confusion matrix.
- But even if we made one confusion matrix for every single threshold that mattered, it would still be too large a number of confusion matrices.

Solution is to use: 
**Receiver Operator Characteristic** ([[ROC]]) graphs which provide a simple way to summarize all of the information.
![[Screen Shot 2024-12-22 at 15.33.30 PM.png|400]]

- The Y-axis shows the True Positive Rate (TPR) which is the same as Sensitivity.
	- ![[Screen Shot 2024-12-22 at 15.35.58 PM.png|400]]
	- True Positive Rate tells you what proportion of Obese (positive) samples were correctly classified.
- The X-axis shows the False Positive Rate (FPR) which is (1-Specificity).
	- ![[Screen Shot 2024-12-22 at 15.39.20 PM.png|400]]
	- False Positive Rate tells you the proportion of not obese samples that were incorrectly classified and are False Positives.
	